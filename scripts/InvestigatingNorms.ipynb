{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Goal of this notebook: Investigate the relationship between the codebooks norm sizes and their frequency in our dataset\n",
    "\n",
    "Theory: Since codebook norms are initialized to be between 0 and 2 in the -1 to 1 square, we expect the codebooks to have the most information, that is; Those who have locked unto a latent variable representation, to be outside of this square and therefore have a norm greater than 2.\n",
    "\n",
    "Why it is important to investigate: When we normalize our latent variables, they're bound to land into the -1 to 1 square. If the density of codebooks in this square is very high (we have a lot of codebooks,) there could be a great deal of chance involved in whether or not a codebook stays locked unto a latent representation.\n",
    "\n",
    "This might result in sudden drifts between latent representation and codebooks, which is exploratorively speaking better, but which makes the training time take longer. As we do not have a lot of training time, we should try to avoid this.\n",
    "\n",
    "### Step 0:\n",
    "- Load the model\n",
    "- Prepare the dataloader\n",
    "\n",
    "### Step 1:\n",
    "- Load N samples\n",
    "- Pass them through the quantizer\n",
    "- Record which codebooks appear\n",
    "- Record the sizes of their norms\n",
    "\n",
    "### Step 2:\n",
    "- Visualize the overall distribution of codebook norms\n",
    "- Visualize the distribution of codebook norms dependent on our dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataloader.gdrive.GDriveHandler import GDrive_Handler\n",
    "import numpy as np\n",
    "import pytorch_lightning.core as L\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import dataloader.GDriveDataloading as GDTL\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image,ImageShow\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import main\n",
    "import taming.modules.losses.vqperceptual\n",
    "from taming.models.vqgan import LAPVQ\n",
    "from taming.models.cond_transformer import Net2NetTransformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  params:\n",
      "    batch_size: 2\n",
      "    num_workers: 8\n",
      "    train:\n",
      "      params:\n",
      "        coord: true\n",
      "        crop_size: 256\n",
      "        size: 256\n",
      "      target: taming.data.faceshq.FacesHQTrain\n",
      "    validation:\n",
      "      params:\n",
      "        coord: true\n",
      "        crop_size: 256\n",
      "        size: 256\n",
      "      target: taming.data.faceshq.FacesHQValidation\n",
      "  target: main.DataModuleFromConfig\n",
      "model:\n",
      "  base_learning_rate: 4.5e-06\n",
      "  params:\n",
      "    cond_stage_config:\n",
      "      params:\n",
      "        down_factor: 16\n",
      "        n_embed: 1024\n",
      "      target: taming.modules.misc.coord.CoordStage\n",
      "    cond_stage_key: coord\n",
      "    first_stage_config:\n",
      "      params:\n",
      "        ckpt_path: C:\\Users\\DripTooHard\\PycharmProjects\\taming-transformers2\\configs\\faceshq.ckpt\n",
      "        ddconfig:\n",
      "          attn_resolutions:\n",
      "          - 16\n",
      "          ch: 128\n",
      "          ch_mult:\n",
      "          - 1\n",
      "          - 1\n",
      "          - 2\n",
      "          - 2\n",
      "          - 4\n",
      "          double_z: false\n",
      "          dropout: 0.0\n",
      "          in_channels: 3\n",
      "          num_res_blocks: 2\n",
      "          out_ch: 3\n",
      "          resolution: 256\n",
      "          z_channels: 256\n",
      "        embed_dim: 256\n",
      "        lossconfig:\n",
      "          params:\n",
      "            codebook_weight: 1.0\n",
      "            disc_conditional: false\n",
      "            disc_in_channels: 3\n",
      "            disc_start: 30001\n",
      "            disc_weight: 0.8\n",
      "          target: taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator\n",
      "        n_embed: 1024\n",
      "      target: taming.models.vqgan.LAPVQ\n",
      "    transformer_config:\n",
      "      params:\n",
      "        block_size: 512\n",
      "        n_embd: 1024\n",
      "        n_head: 16\n",
      "        n_layer: 24\n",
      "        vocab_size: 1024\n",
      "      target: taming.modules.transformer.mingpt.GPT\n",
      "  target: taming.models.cond_transformer.Net2NetTransformer\n",
      "\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DripTooHard\\PycharmProjects\\taming-transformers2\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DripTooHard\\PycharmProjects\\taming-transformers2\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips\\vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "# Prepare CelebAHQ configurations\n",
    "config_path = fr\"C:\\Users\\DripTooHard\\PycharmProjects\\taming-transformers2\\configs\\faceshq_transformer.yaml\"\n",
    "celebAHQ_config = OmegaConf.load(config_path)\n",
    "print(yaml.dump(OmegaConf.to_container(celebAHQ_config)))\n",
    "\n",
    "# Init model with the chosen architecture and configurations\n",
    "model = Net2NetTransformer(**celebAHQ_config.model.params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net2NetTransformer:\n\tMissing key(s) in state_dict: \"first_stage_model.loss.perceptual_loss.scaling_layer.shift\", \"first_stage_model.loss.perceptual_loss.scaling_layer.scale\", \"first_stage_model.loss.perceptual_loss.net.slice1.0.weight\", \"first_stage_model.loss.perceptual_loss.net.slice1.0.bias\", \"first_stage_model.loss.perceptual_loss.net.slice1.2.weight\", \"first_stage_model.loss.perceptual_loss.net.slice1.2.bias\", \"first_stage_model.loss.perceptual_loss.net.slice2.5.weight\", \"first_stage_model.loss.perceptual_loss.net.slice2.5.bias\", \"first_stage_model.loss.perceptual_loss.net.slice2.7.weight\", \"first_stage_model.loss.perceptual_loss.net.slice2.7.bias\", \"first_stage_model.loss.perceptual_loss.net.slice3.10.weight\", \"first_stage_model.loss.perceptual_loss.net.slice3.10.bias\", \"first_stage_model.loss.perceptual_loss.net.slice3.12.weight\", \"first_stage_model.loss.perceptual_loss.net.slice3.12.bias\", \"first_stage_model.loss.perceptual_loss.net.slice3.14.weight\", \"first_stage_model.loss.perceptual_loss.net.slice3.14.bias\", \"first_stage_model.loss.perceptual_loss.net.slice4.17.weight\", \"first_stage_model.loss.perceptual_loss.net.slice4.17.bias\", \"first_stage_model.loss.perceptual_loss.net.slice4.19.weight\", \"first_stage_model.loss.perceptual_loss.net.slice4.19.bias\", \"first_stage_model.loss.perceptual_loss.net.slice4.21.weight\", \"first_stage_model.loss.perceptual_loss.net.slice4.21.bias\", \"first_stage_model.loss.perceptual_loss.net.slice5.24.weight\", \"first_stage_model.loss.perceptual_loss.net.slice5.24.bias\", \"first_stage_model.loss.perceptual_loss.net.slice5.26.weight\", \"first_stage_model.loss.perceptual_loss.net.slice5.26.bias\", \"first_stage_model.loss.perceptual_loss.net.slice5.28.weight\", \"first_stage_model.loss.perceptual_loss.net.slice5.28.bias\", \"first_stage_model.loss.perceptual_loss.lin0.model.1.weight\", \"first_stage_model.loss.perceptual_loss.lin1.model.1.weight\", \"first_stage_model.loss.perceptual_loss.lin2.model.1.weight\", \"first_stage_model.loss.perceptual_loss.lin3.model.1.weight\", \"first_stage_model.loss.perceptual_loss.lin4.model.1.weight\", \"first_stage_model.loss.discriminator.main.0.weight\", \"first_stage_model.loss.discriminator.main.0.bias\", \"first_stage_model.loss.discriminator.main.2.weight\", \"first_stage_model.loss.discriminator.main.3.weight\", \"first_stage_model.loss.discriminator.main.3.bias\", \"first_stage_model.loss.discriminator.main.3.running_mean\", \"first_stage_model.loss.discriminator.main.3.running_var\", \"first_stage_model.loss.discriminator.main.5.weight\", \"first_stage_model.loss.discriminator.main.6.weight\", \"first_stage_model.loss.discriminator.main.6.bias\", \"first_stage_model.loss.discriminator.main.6.running_mean\", \"first_stage_model.loss.discriminator.main.6.running_var\", \"first_stage_model.loss.discriminator.main.8.weight\", \"first_stage_model.loss.discriminator.main.9.weight\", \"first_stage_model.loss.discriminator.main.9.bias\", \"first_stage_model.loss.discriminator.main.9.running_mean\", \"first_stage_model.loss.discriminator.main.9.running_var\", \"first_stage_model.loss.discriminator.main.11.weight\", \"first_stage_model.loss.discriminator.main.11.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[46], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mDripTooHard\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mPycharmProjects\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mtaming-transformers2\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mconfigs\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mfaceshq.ckpt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      3\u001B[0m sd \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(ckpt_path, map_location\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m----> 4\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m missing, unexpected \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mload_state_dict(sd, strict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#Put model in evaluation mode\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\taming-transformers2\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:2152\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[1;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[0;32m   2147\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[0;32m   2148\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2149\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[0;32m   2151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2152\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2153\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[0;32m   2154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for Net2NetTransformer:\n\tMissing key(s) in state_dict: \"first_stage_model.loss.perceptual_loss.scaling_layer.shift\", \"first_stage_model.loss.perceptual_loss.scaling_layer.scale\", \"first_stage_model.loss.perceptual_loss.net.slice1.0.weight\", \"first_stage_model.loss.perceptual_loss.net.slice1.0.bias\", \"first_stage_model.loss.perceptual_loss.net.slice1.2.weight\", \"first_stage_model.loss.perceptual_loss.net.slice1.2.bias\", \"first_stage_model.loss.perceptual_loss.net.slice2.5.weight\", \"first_stage_model.loss.perceptual_loss.net.slice2.5.bias\", \"first_stage_model.loss.perceptual_loss.net.slice2.7.weight\", \"first_stage_model.loss.perceptual_loss.net.slice2.7.bias\", \"first_stage_model.loss.perceptual_loss.net.slice3.10.weight\", \"first_stage_model.loss.perceptual_loss.net.slice3.10.bias\", \"first_stage_model.loss.perceptual_loss.net.slice3.12.weight\", \"first_stage_model.loss.perceptual_loss.net.slice3.12.bias\", \"first_stage_model.loss.perceptual_loss.net.slice3.14.weight\", \"first_stage_model.loss.perceptual_loss.net.slice3.14.bias\", \"first_stage_model.loss.perceptual_loss.net.slice4.17.weight\", \"first_stage_model.loss.perceptual_loss.net.slice4.17.bias\", \"first_stage_model.loss.perceptual_loss.net.slice4.19.weight\", \"first_stage_model.loss.perceptual_loss.net.slice4.19.bias\", \"first_stage_model.loss.perceptual_loss.net.slice4.21.weight\", \"first_stage_model.loss.perceptual_loss.net.slice4.21.bias\", \"first_stage_model.loss.perceptual_loss.net.slice5.24.weight\", \"first_stage_model.loss.perceptual_loss.net.slice5.24.bias\", \"first_stage_model.loss.perceptual_loss.net.slice5.26.weight\", \"first_stage_model.loss.perceptual_loss.net.slice5.26.bias\", \"first_stage_model.loss.perceptual_loss.net.slice5.28.weight\", \"first_stage_model.loss.perceptual_loss.net.slice5.28.bias\", \"first_stage_model.loss.perceptual_loss.lin0.model.1.weight\", \"first_stage_model.loss.perceptual_loss.lin1.model.1.weight\", \"first_stage_model.loss.perceptual_loss.lin2.model.1.weight\", \"first_stage_model.loss.perceptual_loss.lin3.model.1.weight\", \"first_stage_model.loss.perceptual_loss.lin4.model.1.weight\", \"first_stage_model.loss.discriminator.main.0.weight\", \"first_stage_model.loss.discriminator.main.0.bias\", \"first_stage_model.loss.discriminator.main.2.weight\", \"first_stage_model.loss.discriminator.main.3.weight\", \"first_stage_model.loss.discriminator.main.3.bias\", \"first_stage_model.loss.discriminator.main.3.running_mean\", \"first_stage_model.loss.discriminator.main.3.running_var\", \"first_stage_model.loss.discriminator.main.5.weight\", \"first_stage_model.loss.discriminator.main.6.weight\", \"first_stage_model.loss.discriminator.main.6.bias\", \"first_stage_model.loss.discriminator.main.6.running_mean\", \"first_stage_model.loss.discriminator.main.6.running_var\", \"first_stage_model.loss.discriminator.main.8.weight\", \"first_stage_model.loss.discriminator.main.9.weight\", \"first_stage_model.loss.discriminator.main.9.bias\", \"first_stage_model.loss.discriminator.main.9.running_mean\", \"first_stage_model.loss.discriminator.main.9.running_var\", \"first_stage_model.loss.discriminator.main.11.weight\", \"first_stage_model.loss.discriminator.main.11.bias\". "
     ]
    }
   ],
   "source": [
    "#Load checkpoints\n",
    "ckpt_path = r\"C:\\Users\\DripTooHard\\PycharmProjects\\taming-transformers2\\configs\\faceshq.ckpt\"\n",
    "sd = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "model.load_state_dict(sd)\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "\n",
    "#Put model in evaluation mode\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Initializing the dataloader\n",
    "ID_DF_Path = r\"C:\\Users\\DripTooHard\\PycharmProjects\\taming-transformers2\\scripts\\dataloader\\gdrive\\FFHQimages.csv\"\n",
    "config_path = r\"C:\\Users\\DripTooHard\\PycharmProjects\\taming-transformers2\\configs\\gdrive_FFHQ.yaml\"\n",
    "scopes = [\"https://www.googleapis.com/auth/drive.readonly\"]\n",
    "creds_path = r\"C:\\Users\\DripTooHard\\PycharmProjects\\taming-transformers2\\scripts\\dataloader\\gdrive\\deep-learning-2023-405822-135193813109.json\"\n",
    "access_token_path = r\"C:\\Users\\DripTooHard\\PycharmProjects\\taming-transformers2\\scripts\\dataloader\\test.json\"\n",
    "\n",
    "GDDataloader = GDTL.ImagesDatamodule(ID_DF_Path,scopes,creds_path,num_workers=0,batch_size=1)\n",
    "prop_dict = dict({\"val\":0.1,\"test\":0.1,\"train\":0.8})\n",
    "GDDataloader.setup(prop_dict)\n",
    "\n",
    "train_dataloader = iter(GDDataloader.train_dataloader())\n",
    "#We visualize the image\n",
    "plt.imshow(next(train_dataloader)[0].permute(1,2,0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting empirical codebooks\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#number of samples we want\n",
    "N= 100\n",
    "\n",
    "# DataFrame to store vectors and their norms\n",
    "empirical_norms = []\n",
    "\n",
    "#Get N samples\n",
    "for n in range(N):\n",
    "    image = next(train_dataloader)\n",
    "    encoded_z = model.first_stage_model.encoder(image)\n",
    "    zq = encoded_z.permute(0,2,3,1)\n",
    "\n",
    "    # List to store the vectors\n",
    "    vectors = []\n",
    "\n",
    "    # Iterate over the 64x64 grid\n",
    "    for i in range(zq.shape[1]):   # iterating over the first 64\n",
    "        for j in range(zq.shape[2]):   # iterating over the second 64\n",
    "            # Extract the vector and store it\n",
    "            vector = zq[0, i, j, :]   # this gives you the [256] vector\n",
    "\n",
    "            norm = np.linalg.norm(vector)\n",
    "            above_abs_1 = [x for x in vector if abs(x)>1]\n",
    "            percentage_above_1 = len(above_abs_1)/len(vector)\n",
    "            # Append to the DataFrame\n",
    "            empirical_norms.append({'Vector': vector, 'Norm': norm,\"Normalized norm\":norm/256,'Percentage_above_1':percentage_above_1})\n",
    "\n",
    "\n",
    "\n",
    "empirical_norms_DF = pd.DataFrame.from_dict(empirical_norms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb.histplot(empirical_norms_DF[\"Normalized norm\"],stat=\"probability\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb.histplot(empirical_norms_DF[\"Norm\"],stat=\"probability\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb.histplot(empirical_norms_DF[\"Percentage_above_1\"],stat=\"probability\",bins=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "empirical_norms_DF.to_csv(\"empirical_norms_FFHQ_pretrained\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: ylabel='Probability'>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We look at the codebook to check whether or not it ressembles a normal distribution around 0.\n",
    "\n",
    "norms = []\n",
    "\n",
    "#Uncomment the code below to get a graph of how the freshly initialized codebook should look.\n",
    "model.first_stage_model.quantize.embedding.weight.data.uniform_(-1.0/(model.first_stage_model.quantize.n_e),1/(model.first_stage_model.quantize.n_e))\n",
    "\n",
    "for codebook in model.first_stage_model.quantize.parameters():\n",
    "    for zq_codebook in codebook:\n",
    "        norms += [np.linalg.norm(zq_codebook)]\n",
    "\n",
    "#We know for a fact, that all norms will be equal to or less than 2 if it has just been instantiated\n",
    "#assert(len([norm for norm in norms if norm>2])>0)\n",
    "\n",
    "sb.histplot(norms,bins=20,stat=\"probability\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}